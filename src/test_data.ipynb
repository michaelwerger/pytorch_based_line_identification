{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "\n",
    "import shutil\n",
    "import glob\n",
    "import random\n",
    "\n",
    "from datetime import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH= os.path.join(os.getcwd(), '..','data','train')\n",
    "TEST_DATA_PATH = os.path.join(os.getcwd(), '..','data','test')\n",
    "MODEL_PATH = os.path.join(os.getcwd(), '..','data','model.h5')\n",
    "\n",
    "IMAGE_SIZE = 32; \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lädt ein Bild\n",
    "def load_image(path,image_size=IMAGE_SIZE):\n",
    "    img =cv2.imread(path)\n",
    "    img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    tmp = img.reshape([IMAGE_SIZE, IMAGE_SIZE,1])\n",
    "\n",
    "\n",
    "    return np.array(tmp)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test auf Dataset\n",
    "def test_dataset(model, labels_decoded, path, image_size=IMAGE_SIZE):\n",
    "    correct_matches = 0\n",
    "    result_table = PrettyTable()\n",
    "    result_table.field_names = [\"Datei \", \"Ist\", \"Dekodiert\", \"Max. Pred.\", \"Match?\"]\n",
    "\n",
    "    for filename in sorted(os.listdir(path)):\n",
    "\n",
    "        if(filename.startswith('.') == False):\n",
    "\n",
    "            current_wavelength = filename[0:7]\n",
    "            #print (current_wavelength)\n",
    "            image_path = os.path.join(path,filename)\n",
    "                \n",
    "            test_image = load_image(image_path)\n",
    "            predictions = model.predict(test_image.reshape((1,IMAGE_SIZE,IMAGE_SIZE,1)), verbose=0)\n",
    "                \n",
    "            index_max_predictions = np.argmax(predictions)\n",
    "            #print('index_max_predictions:',index_max_predictions, current_wavelength, labels_decoded[index_max_predictions])\n",
    "            decode_wavelength = labels_decoded[index_max_predictions]\n",
    "\n",
    "            # Passt oder nicht?\n",
    "            if( str.upper(current_wavelength) == str.upper(decode_wavelength)):\n",
    "                result_table.add_row([image_path, current_wavelength, decode_wavelength, str(index_max_predictions), \"✅\" ])\n",
    "                correct_matches = correct_matches + 1 \n",
    "            else:\n",
    "                result_table.add_row([image_path, current_wavelength, decode_wavelength, str(index_max_predictions), \"❌\" ])\n",
    "\n",
    "\n",
    "    print(result_table)\n",
    "\n",
    "    \n",
    "    jetzt = datetime.now()\n",
    "    with open(\"result_table_{}.txt\".format(jetzt.strftime(\"%y-%m-%d-%H-%M-%S\")),\"w\") as result_table_out:\n",
    "        result_table_out.write(str(result_table))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy some training data to directory test, if no test data is provided\n",
    "#\n",
    "# shutil.rmtree(TEST_DATA_PATH)\n",
    "# os.mkdir(TEST_DATA_PATH)\n",
    "# for directory in sorted(os.listdir(TRAIN_DATA_PATH)):\n",
    "#     if(directory.startswith('.') == False):\n",
    "#         p = os.path.join(TRAIN_DATA_PATH,directory)\n",
    "#         for filename in sorted(os.listdir(p)):\n",
    "#             if random.random() > 0.99:\n",
    "#                \n",
    "#                 shutil.copyfile(os.path.join(p,filename),os.path.join(TEST_DATA_PATH,filename))\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels_decoded = []\n",
    "for directory in sorted(os.listdir(TRAIN_DATA_PATH)):\n",
    "    if(directory.startswith('.') == False):\n",
    "        labels_decoded.append(directory)\n",
    "\n",
    "model = load_model(MODEL_PATH)\n",
    "test_dataset(model, labels_decoded, TEST_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
